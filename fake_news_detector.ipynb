{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# FAKE NEWS DETECTOR\n",
    "### A fake news detector using keras and neural networks.\n",
    "### I'm going to use as primary features the title and the author of the article combined in a single feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collected thanks to Kaggle datasets.\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>Darrell Lucus</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n      <td>Daniel J. Flynn</td>\n      <td>Ever get the feeling your life circles the rou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why the Truth Might Get You Fired</td>\n      <td>Consortiumnews.com</td>\n      <td>Why the Truth Might Get You Fired October 29, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n      <td>Jessica Purkiss</td>\n      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian woman jailed for fictional unpublished...</td>\n      <td>Howard Portnoy</td>\n      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "source": [
    "## Data preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do the preprocessing I create a copy of the datasets\n",
    "train_copy = train_data.copy()\n",
    "test_copy = test_data.copy()\n",
    "\n",
    "# fill missing values with an empty string\n",
    "train_copy = train_copy.fillna('')\n",
    "test_copy = test_copy.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with title and author\n",
    "train_copy['final'] = train_copy['author'] + ' ' + train_copy['title']\n",
    "test_copy['final'] = test_copy['author'] + ' ' + test_copy['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\domy-\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# download the stopwords, which are the common words that are not useful for our goal\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming map words to their root forms\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying stemming and some preprocessing\n",
    "for i in range(len(train_copy)):\n",
    "  review = re.sub('[^a-zA-Z]',' ',train_copy['final'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying stemming and some preprocessing to the test data\n",
    "corpus_test = []\n",
    "for i in range(len(test_copy)):\n",
    "  review = re.sub('[^a-zA-Z]',' ',test_copy['final'][i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "  review = ' '.join(review)\n",
    "  corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to one hot representation\n",
    "onehot_rep = [one_hot(words,voc_size)for words in corpus]\n",
    "onehot_rep_test = [one_hot(words,voc_size)for words in corpus_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding Sentences to make them of same size\n",
    "embedded_docs = pad_sequences(onehot_rep,padding='pre',maxlen=25)\n",
    "embedded_docs_test = pad_sequences(onehot_rep_test,padding='pre',maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20800, 5)\n(20800,)\n"
     ]
    }
   ],
   "source": [
    "# split our training dataset to X and y\n",
    "X = train_copy.drop('label',axis=1)\n",
    "y=train_copy['label']\n",
    "y_test = test_copy['label']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "# Creating and training model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 25, 40)            200000    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 25, 40)            0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               56400     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                6464      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 262,929\nTrainable params: 262,929\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "# I have used embedding layers with LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,40,input_length=25))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20800, 25), (20800,), (20800, 25))"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "#Converting into numpy array\n",
    "X_final = np.array(embedded_docs)\n",
    "y_final = np.array(y)\n",
    "test_final = np.array(embedded_docs_test)\n",
    "X_final.shape,y_final.shape,test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "325/325 [==============================] - 15s 35ms/step - loss: 0.3431 - accuracy: 0.8316\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 11s 35ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0121 - accuracy: 0.9958\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 12s 37ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 11s 35ms/step - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 12s 37ms/step - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 12s 37ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 11s 35ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 8.3801e-04 - accuracy: 0.9997\n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 9.6353e-04 - accuracy: 0.9998\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 11s 35ms/step - loss: 8.7727e-04 - accuracy: 0.9997\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 12s 37ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 12s 36ms/step - loss: 8.5289e-04 - accuracy: 0.9997\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 9s 29ms/step - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 6s 20ms/step - loss: 0.0017 - accuracy: 0.9994\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22be8568f70>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "#training model\n",
    "model.fit(X_final,y_final,epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   id  label\n0   0      1\n1   1      0\n2   2      1\n3   3      1\n4   4      1\n"
     ]
    }
   ],
   "source": [
    "#results = model.predict_classes(test_final)\n",
    "y_pred = (model.predict(test_final) > 0.5).astype(\"int32\")\n",
    "\n",
    "final_sub = pd.DataFrame()\n",
    "final_sub['id']=test_copy['id']\n",
    "final_sub['label'] = y_pred\n",
    "print(final_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        count += 1\n",
    "\n",
    "print(count / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}